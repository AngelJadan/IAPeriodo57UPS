{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesos de decisión de Markov.\n",
    "\n",
    "Los MDP (Procesos de Decision de Markov) una forma idealizada matematicamente del problema de aprendizaje por refuerzo, para el cual se podría encontrar un enunciado teórico preciso que pueda describirla.\n",
    "\n",
    "#### Propiedad de Markov.\n",
    "\n",
    "Esta propiedad de Markov nos muestra que el futuro es independiente del pasado, dado el presente, expresado de la siguiente forma.\n",
    "\n",
    "$P [\\mathbf{S}_t+_1 ]=P[\\mathbf{S}_t+_1 | \\mathbf{S}_1,_..., \\mathbf{S}_t]$\n",
    "\n",
    "Donde $ \\mathbf{S}_t $ representa el el estado actual y contiene toda la información relevante de los estados pasados $ \\mathbf{S}_1,_...,\\mathbf{S}_t $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
